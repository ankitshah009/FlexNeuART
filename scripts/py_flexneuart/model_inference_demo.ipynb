{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the repo is cloned, all necessary packages are installed, including calling the script:\n",
    "\n",
    "```./install_packages.sh```\n",
    "\n",
    "and the code is compiled:\n",
    "\n",
    "```./build.sh```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing directory to the repo root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading demo data\n",
    "\n",
    "1. Download [this file from our Google Drive](https://drive.google.com/file/d/1p2H-tjdMe69oIJXX0xEIpLLNbHrkO4Xy/view?usp=sharing) and copy it to the source root directory, where it should be unpacked. As a result, a source directory should contain a sub-directory ``collections/msmarco_doc``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: statistics on downloaded data should look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "Checking data sub-directory: bitext\n",
      "Checking data sub-directory: bitext_msmarco_pass_mixed_qrels\n",
      "Checking data sub-directory: bitext_msmarco_pass_part0\n",
      "Checking data sub-directory: bitext_msmarco_pass_part1\n",
      "Checking data sub-directory: bitext_msmarco_pass_part2\n",
      "Checking data sub-directory: bitext_msmarco_pass_pseudo_qrels\n",
      "Checking data sub-directory: bitext_orcas_minqty_5\n",
      "Checking data sub-directory: dev\n",
      "Checking data sub-directory: dev1\n",
      "Checking data sub-directory: dev2\n",
      "Checking data sub-directory: dev2.single_doc_query\n",
      "Checking data sub-directory: docs\n",
      "Found indexable data file: docs/AnswerFields.jsonl.gz\n",
      "Checking data sub-directory: lb2020\n",
      "Checking data sub-directory: test2019\n",
      "Checking data sub-directory: test2020\n",
      "Checking data sub-directory: train1\n",
      "Checking data sub-directory: train.dont_use\n",
      "Found query file: bitext/QuestionFields.jsonl\n",
      "Found query file: bitext_msmarco_pass_mixed_qrels/QuestionFields.jsonl\n",
      "Found query file: bitext_msmarco_pass_part0/QuestionFields.jsonl\n",
      "Found query file: bitext_msmarco_pass_part1/QuestionFields.jsonl\n",
      "Found query file: bitext_msmarco_pass_part2/QuestionFields.jsonl\n",
      "Found query file: bitext_msmarco_pass_pseudo_qrels/QuestionFields.jsonl\n",
      "Found query file: bitext_orcas_minqty_5/QuestionFields.jsonl\n",
      "Found query file: dev/QuestionFields.jsonl\n",
      "Found query file: dev1/QuestionFields.jsonl\n",
      "Found query file: dev2/QuestionFields.jsonl\n",
      "Found query file: dev2.single_doc_query/QuestionFields.jsonl\n",
      "Found query file: lb2020/QuestionFields.jsonl\n",
      "Found query file: test2019/QuestionFields.jsonl\n",
      "Found query file: test2020/QuestionFields.jsonl\n",
      "Found query file: train1/QuestionFields.jsonl\n",
      "Found query file: train.dont_use/QuestionFields.jsonl\n",
      "getIndexQueryDataInfo return value:  docs AnswerFields.jsonl.gz ,bitext,bitext_msmarco_pass_mixed_qrels,bitext_msmarco_pass_part0,bitext_msmarco_pass_part1,bitext_msmarco_pass_part2,bitext_msmarco_pass_pseudo_qrels,bitext_orcas_minqty_5,dev,dev1,dev2,dev2.single_doc_query,lb2020,test2019,test2020,train1,train.dont_use QuestionFields.jsonl\n",
      "Using the data input files: AnswerFields.jsonl.gz, QuestionFields.jsonl\n",
      "Index dirs: docs\n",
      "Query dirs:  bitext bitext_msmarco_pass_mixed_qrels bitext_msmarco_pass_part0 bitext_msmarco_pass_part1 bitext_msmarco_pass_part2 bitext_msmarco_pass_pseudo_qrels bitext_orcas_minqty_5 dev dev1 dev2 dev2.single_doc_query lb2020 test2019 test2020 train1 train.dont_use\n",
      "Queries/questions:\n",
      "bitext 357013\n",
      "bitext_msmarco_pass_mixed_qrels 787462\n",
      "bitext_msmarco_pass_part0 262911\n",
      "bitext_msmarco_pass_part1 262911\n",
      "bitext_msmarco_pass_part2 262909\n",
      "bitext_msmarco_pass_pseudo_qrels 787462\n",
      "bitext_orcas_minqty_5 910899\n",
      "dev 5193\n",
      "dev1 2500\n",
      "dev2 2693\n",
      "dev2.single_doc_query 1\n",
      "lb2020 5793\n",
      "test2019 43\n",
      "test2020 45\n",
      "train1 10000\n",
      "train.dont_use 367013\n",
      "Documents/passages/answers:\n",
      "docs 44860979\n"
     ]
    }
   ],
   "source": [
    "!scripts/report/get_basic_collect_stat.sh msmarco_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing (each step takes a few hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucene index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/index/create_lucene_index.sh msmarco_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward indices (text is not really necessary for this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts/index/create_fwd_index.sh msmarco_doc mapdb \"text:parsedText text_raw:raw\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-07 13:44:14--  http://boytsov.info/models/msmarco_doc/2019/bert_vanilla/model.best\n",
      "Resolving boytsov.info (boytsov.info)... 69.60.127.165\n",
      "Connecting to boytsov.info (boytsov.info)|69.60.127.165|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 438863972 (419M) [text/plain]\n",
      "Saving to: ‘model.best’\n",
      "\n",
      "model.best          100%[===================>] 418.53M  3.08MB/s    in 2m 26s  \n",
      "\n",
      "2021-02-07 13:46:41 (2.86 MB/s) - ‘model.best’ saved [438863972/438863972]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget boytsov.info/models/msmarco_doc/2019/bert_vanilla/model.best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we do inference on CPU, which is pretty slow. To use a GPU change the ``DEVICE_NAME``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanillaBertRanker(\n",
       "  (bert): CustomBertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.05, inplace=False)\n",
       "  (cls): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#DEVICE_NAME='cuda:0'\n",
    "MAX_QUERY_LEN=32\n",
    "MAX_DOC_LEN=512 - 32 - 3\n",
    "DEVICE_NAME='cpu'\n",
    "MODEL_FILE='model.best'\n",
    "model=torch.load(MODEL_FILE, map_location='cpu')\n",
    "model.to(DEVICE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference/API demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION='msmarco_doc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DOCNO': '961921',\n",
       " 'text': 'national park system establish',\n",
       " 'text_raw': 'when was the national park system established',\n",
       " 'text_bert_tok': 'when was the national park system established'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY_JSON={\"DOCNO\": \"961921\", \n",
    "            \"text\": \"national park system establish\",\n",
    "             \"text_raw\": \"when was the national park system established\", \"text_bert_tok\": \"when was the national park system established\"}\n",
    "QUERY_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.config import DOCID_FIELD, TEXT_FIELD_NAME, TEXT_RAW_FIELD_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.setup import *\n",
    "# add Java JAR to the class path\n",
    "configure_classpath('target')\n",
    "# create a resource manager\n",
    "resource_manager=create_featextr_resource_manager(f'collections/{COLLECTION}/forward_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.cand_provider import *\n",
    "# create a candidate provider/generator\n",
    "cand_prov = create_cand_provider(resource_manager, PROVIDER_TYPE_LUCENE, f'collections/{COLLECTION}/lucene_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1204206,\n",
       " [CandidateEntry(doc_id='D2527574', score=18.659997940063477),\n",
       "  CandidateEntry(doc_id='D2398015', score=18.492298126220703),\n",
       "  CandidateEntry(doc_id='D1578785', score=18.234092712402344),\n",
       "  CandidateEntry(doc_id='D2189735', score=18.2298583984375),\n",
       "  CandidateEntry(doc_id='D1578782', score=17.947647094726562),\n",
       "  CandidateEntry(doc_id='D2527573', score=17.892498016357422),\n",
       "  CandidateEntry(doc_id='D1578784', score=17.88416862487793),\n",
       "  CandidateEntry(doc_id='D2106902', score=17.869140625),\n",
       "  CandidateEntry(doc_id='D2591882', score=17.70314598083496),\n",
       "  CandidateEntry(doc_id='D2443070', score=17.63814926147461),\n",
       "  CandidateEntry(doc_id='D1578783', score=17.51651382446289),\n",
       "  CandidateEntry(doc_id='D3525662', score=17.447235107421875),\n",
       "  CandidateEntry(doc_id='D2769926', score=17.322866439819336),\n",
       "  CandidateEntry(doc_id='D1737386', score=17.243505477905273),\n",
       "  CandidateEntry(doc_id='D1514002', score=17.16539192199707),\n",
       "  CandidateEntry(doc_id='D14552', score=17.148212432861328),\n",
       "  CandidateEntry(doc_id='D2443068', score=17.124448776245117),\n",
       "  CandidateEntry(doc_id='D2893132', score=17.09151268005371),\n",
       "  CandidateEntry(doc_id='D1581803', score=17.08568572998047),\n",
       "  CandidateEntry(doc_id='D1462277', score=17.0462589263916)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text=QUERY_JSON[TEXT_FIELD_NAME]\n",
    "query_toks=query_text.split()\n",
    "run_query(cand_prov, 20, query_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve a document (D1578782 is marked as a relevant entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.fwd_index import get_forward_index\n",
    "raw_indx = get_forward_index(resource_manager, 'text_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_ID='D1578782' # relevant\n",
    "#DOC_ID='D1462277' # not marked as relevant\n",
    "doc_text=raw_indx.get_doc_raw(DOC_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "national park system establish\n",
      "\n",
      "national park mashups \"national park service's 100 year birthday is in 2016. august 25, 2016 is the 100th birthday of the national park service. starting with yellowstone in 1872 there are over 400 units in the national park service today. how old is the system? the national park service was created by an act of congress and signed by president woodrow wilson on august 25, 1916. yellowstone national park was established by an act signed by president ulysses s. grant on march 1, 1872, as the nation's first national park. the mission of the national park service: the national park service preserves unimpaired the natural and cultural resources and values of the national park system for the enjoyment, education, and inspiration of this and future generations. the national park service cooperates with partners to extend the benefits of natural and cultural resource conservation and outdoor recreation throughout this country and the world. national park mashups news, videos, tweets, pictures, map blue ridge parkway cuyahoga valley national park grand canyon national park grand teton national park great smoky mountains national park olympic national park rocky mountain national park white sands national monument yellowstone national park yosemite national park zion national park how many areas are in the national park system? the national park system comprises 401 areas called \"\"units\"\" covering more than 84 million acres. these units include national parks, monuments, battlefields, military parks, historical parks, historic sites, lakeshores, recreation areas, scenic rivers and trails, and the white house. who are the people of the national park service? the national park service employs approximately 20,000 diverse professionals – permanent, temporary, and seasonal. they are assisted by nearly 140,000 volunteers-in-parks (vips) who donate over 5 million hours each year.©2006-present. all rights reserved. this site is not affiliated with the national park service, the us government or any us government agency. \"\n"
     ]
    }
   ],
   "source": [
    "print(query_text)\n",
    "print()\n",
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the document against the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2120, 2380, 2291, 5323]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_bert_tok = model.tokenize(query_text)\n",
    "query_bert_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2120, 2380, 16137, 6979, 4523, 1000, 2120, 2380, 2326, 1005, 1055, 2531, 2095, 5798, 2003, 1999, 2355, 1012, 2257, 2423, 1010, 2355, 2003, 1996, 16919, 5798, 1997, 1996, 2120, 2380, 2326, 1012, 3225, 2007, 29231, 1999, 7572, 2045, 2024, 2058, 4278, 3197, 1999, 1996, 2120, 2380, 2326, 2651, 1012, 2129, 2214, 2003, 1996, 2291, 1029, 1996, 2120, 2380, 2326, 2001, 2580, 2011, 2019, 2552, 1997, 3519, 1998, 2772, 2011, 2343, 23954, 4267, 2006, 2257, 2423, 1010, 4947, 1012, 29231, 2120, 2380, 2001, 2511, 2011, 2019, 2552, 2772, 2011, 2343, 22784, 1055, 1012, 3946, 2006, 2233, 1015, 1010, 7572, 1010, 2004, 1996, 3842, 1005, 1055, 2034, 2120, 2380, 1012, 1996, 3260, 1997, 1996, 2120, 2380, 2326, 1024, 1996, 2120, 2380, 2326, 18536, 4895, 5714, 4502, 27559, 1996, 3019, 1998, 3451, 4219, 1998, 5300, 1997, 1996, 2120, 2380, 2291, 2005, 1996, 20195, 1010, 2495, 1010, 1998, 7780, 1997, 2023, 1998, 2925, 8213, 1012, 1996, 2120, 2380, 2326, 17654, 2015, 2007, 5826, 2000, 7949, 1996, 6666, 1997, 3019, 1998, 3451, 7692, 5680, 1998, 7254, 8640, 2802, 2023, 2406, 1998, 1996, 2088, 1012, 2120, 2380, 16137, 6979, 4523, 2739, 1010, 6876, 1010, 1056, 28394, 3215, 1010, 4620, 1010, 4949, 2630, 5526, 12602, 12731, 17560, 18170, 3028, 2120, 2380, 2882, 8399, 2120, 2380, 2882, 8915, 2669, 2120, 2380, 2307, 20629, 4020, 2120, 2380, 4386, 2120, 2380, 6857, 3137, 2120, 2380, 2317, 13457, 2120, 6104, 29231, 2120, 2380, 10930, 3366, 23419, 2120, 2380, 19999, 2120, 2380, 2129, 2116, 2752, 2024, 1999, 1996, 2120, 2380, 2291, 1029, 1996, 2120, 2380, 2291, 8681, 22649, 2752, 2170, 1000, 1000, 3197, 1000, 1000, 5266, 2062, 2084, 6391, 2454, 4631, 1012, 2122, 3197, 2421, 2120, 6328, 1010, 10490, 1010, 11686, 2015, 1010, 2510, 6328, 1010, 3439, 6328, 1010, 3181, 4573, 1010, 6597, 16892, 2015, 1010, 8640, 2752, 1010, 12916, 5485, 1998, 9612, 1010, 1998, 1996, 2317, 2160, 1012, 2040, 2024, 1996, 2111, 1997, 1996, 2120, 2380, 2326, 1029, 1996, 2120, 2380, 2326, 13495, 3155, 2322, 1010, 2199, 7578, 8390, 1516, 4568, 1010, 5741, 1010, 1998, 12348, 1012, 2027, 2024, 7197, 2011, 3053, 8574, 1010, 2199, 7314, 1011, 1999, 1011, 6328, 1006, 21722, 2015, 1007, 2040, 21357, 2058, 1019, 2454, 2847, 2169, 2095, 1012, 1075, 28332, 2575, 1011, 2556, 1012, 2035, 2916, 9235, 1012, 2023, 2609, 2003, 2025, 6989, 2007, 1996, 2120, 2380, 2326, 1010, 1996, 2149, 2231, 2030, 2151, 2149, 2231, 4034, 1012, 1000] 393\n"
     ]
    }
   ],
   "source": [
    "doc_bert_tok = model.tokenize(doc_text)\n",
    "print(doc_bert_tok, len(doc_bert_tok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is important to truncate queries and documents ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_bert_tok=query_bert_tok[0:MAX_QUERY_LEN]\n",
    "doc_bert_tok=doc_bert_tok[0:MAX_DOC_LEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... and pad queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2120, 2380, 2291, 5323, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "from scripts.cedr.data import PAD_CODE\n",
    "\n",
    "query_bert_tok_pad = query_bert_tok + [PAD_CODE] * (MAX_QUERY_LEN - len(query_bert_tok))\n",
    "print(query_bert_tok_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .unsqueeze(0) is required to create a batch dimension (we can have multiple queries & documents batched together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 393)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tok_tensor_pad = torch.LongTensor(query_bert_tok_pad).unsqueeze(0).to(DEVICE_NAME)\n",
    "doc_tok_tensor = torch.LongTensor(doc_bert_tok).unsqueeze(0).to(DEVICE_NAME)\n",
    "len(query_tok_tensor_pad[0]), len(doc_tok_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32]), torch.Size([1, 393]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tok_tensor_pad.shape, doc_tok_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_mask = torch.FloatTensor([1.0] * len(query_bert_tok) + \n",
    "                              [0.] * (MAX_QUERY_LEN - len(query_bert_tok))).unsqueeze(0).to(DEVICE_NAME)\n",
    "doc_mask = torch.ones_like(doc_tok_tensor).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32]), torch.Size([1, 393]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_mask.shape, doc_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_mask, doc_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5071], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(query_tok_tensor_pad, query_mask, doc_tok_tensor, doc_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
